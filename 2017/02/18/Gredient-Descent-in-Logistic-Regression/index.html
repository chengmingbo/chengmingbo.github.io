<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="ML,">





  <link rel="alternate" href="/atom.xml" title="Mingbo" type="application/atom+xml">






<meta name="description" content="As a simple model, Logistic regression is very popular in Machine Learning, especially in computer industry while gradient descent is more of popularity as well among dozens of optimization methods. T">
<meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="Gradient Descent in Logistic Regression">
<meta property="og:url" content="http://commanber.com/2017/02/18/Gredient-Descent-in-Logistic-Regression/index.html">
<meta property="og:site_name" content="Mingbo">
<meta property="og:description" content="As a simple model, Logistic regression is very popular in Machine Learning, especially in computer industry while gradient descent is more of popularity as well among dozens of optimization methods. T">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-03-10T09:13:43.827Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Gradient Descent in Logistic Regression">
<meta name="twitter:description" content="As a simple model, Logistic regression is very popular in Machine Learning, especially in computer industry while gradient descent is more of popularity as well among dozens of optimization methods. T">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://commanber.com/2017/02/18/Gredient-Descent-in-Logistic-Regression/">





  <title>Gradient Descent in Logistic Regression | Mingbo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Mingbo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-slides">
          <a href="/slides/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-area-chart"></i> <br>
            
            slides
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://commanber.com/2017/02/18/Gredient-Descent-in-Logistic-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mingbo Cheng">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mingbo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Gradient Descent in Logistic Regression</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-18T14:33:10+01:00">
                2017-02-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>As a simple model, Logistic regression is very popular in Machine Learning, especially in computer industry while gradient descent is more of popularity as well among dozens of optimization methods. The aim of this article is to demonstrate how to reach these formulas conclusion. </p>
<h3 id="1-Model-a-problem"><a href="#1-Model-a-problem" class="headerlink" title="1. Model a problem"></a>1. Model a problem</h3><p>First of all, we know that Logistic regression is a statistical model. Suppose we have a coin, we’d like to know the probability of the head and tail. Bernoulli distribution is a good distribution to model the coin. The hyphothsis is as followed:<br>$$P(y=1|\mu)=\mu  \qquad(1)$$.  </p>
<p>$y=1$ means the probability of the head, then $y=0$ is that of the tail. $\mu$ here is the parameter, if $\mu=0.5$, then the probability of head equals to 0.5, which means we have half the probabilty reach the head as well as the tail. Now we have:<br>$$P(y=0|\mu)=1-\mu\qquad(2)$$ </p>
<p>If we take a look at these two formula, we can conclude a more general formula:<br> $$P(y|\mu)={\mu}^y\cdot{(1-\mu)}^{(1-y)} \qquad(3)$$</p>
<p>Let’s test it, $y$ only have two value $0$ and $1$, if $y=1$, $P(y|\mu)=\mu$, othewise, $P(y|\mu)=1-\mu$. Suppose we have a dataset $D={y_1,y_2,y_3…y_m}$ observed values, we want to estimate the parameter $\mu$, the problems become following question:<br>$$P(\mu|D)=?\qquad (4)$$</p>
<h3 id="2-Estimate-Parameter"><a href="#2-Estimate-Parameter" class="headerlink" title="2. Estimate Parameter"></a>2. Estimate Parameter</h3><p>We use Bayes formula to transfer the problem to another:<br>$$P(\mu|D)=\frac{P(D|\mu)\cdot P(\mu)}{P(D)}=\frac{P(y_1,y_2,y_3…,y_m|\mu)\cdot P(\mu)}{P(D)}\qquad (5)$$</p>
<p>Here denominator $P(D)$ is a constant as well as $P(\mu)$ if we see $\mu$ as variable rather than a distribution. Then we have:<br>$$P(\mu|D)\triangleq P(y_1,y_2,y_3…,y_m|\mu) \qquad(6)$$</p>
<p>We can find a series of $\mu$(e.g, $\mu=0.1, \mu=0.72$), but we should find the maximum $P(\mu|D)$, because when $P(\mu|D)$ reaches its max means $\mu$ most likely is the right parameter. We assume that each $y$ is independent from the others given the parameter $\mu$. then we have:<br>$$P(\mu|D)\triangleq P(y_1|\mu)P(y_2|\mu)P(y_3|\mu)…,P(y_m|\mu)={\prod}_{i=1}^{m}P(y_i|\mu)\qquad(7)$$</p>
<p>Now, the problem is to maximize the ${\prod}_{i=1}^{m}P(y_i|\mu)$, that is:<br>$$L = \underset{\mu}{argmax}{\prod}_{i=1}^{m}P(y_i|\mu)=\underset{\mu}{argmax}{\prod}_{i=1}^{m}[{\mu}^y\cdot{(1-\mu)}^{(1-y)}] \qquad(8)$$</p>
<p>It is a little hard to find the maximum, we change the problem to another way:<br>$$L =\underset{\mu}{argmax}ln({\prod}_{i=1}^{m}[{\mu}^y\cdot{(1-\mu)}^{(1-y)}])\qquad(9)$$</p>
<p>Then we have:<br>$$L = \underset{\mu}{argmax}{\sum}_{i=1}^{m}[{y ln(\mu}) + (1-y) ln({1-\mu)}]\qquad(10)$$</p>
<h3 id="3-Logistic-Regression"><a href="#3-Logistic-Regression" class="headerlink" title="3. Logistic Regression"></a>3. Logistic Regression</h3><p>If we let $\mu=h_{\theta}(x)$, then we have:</p>
<p>$$L = \underset{\theta}{argmax}{\sum}_{i=1}^{m}[{y ln(h_{\theta}(x)}) + (1-y) ln({1-h_{\theta}(x))}]\qquad(11)$$</p>
<p>Here,<br>$$h_{\theta}(x)=\frac{1}{1+e^{-(\theta_0 x_0+\theta_1 x_1+\theta_2 x_2+\theta_m x_m)}}=\frac{1}{1+e^{-{\Theta}X}}\qquad (12)$$</p>
<p>$h_{\theta}(x)$ is named sigmoid function and now we use parameter $\theta$ to estimate $\mu$. Simgoid function is a pretty good function, derivative of which is elegant. we let $\sigma=\frac{1}{1+e^{-x}}$, then:</p>
<p>\begin{align}<br>\frac{\partial{\sigma}}{\partial x}<br>&amp;= \frac{-1}{(1+e^{-x})^2}\cdot e^{-x}\cdot(-1)\\<br>&amp;=\frac{e^{-x}}{(1+e^{-x})^2}=\frac{1+e^{-x}-1}{(1+e^{-x})^2}\\<br>&amp;=\frac{1}{1+e^{-x}}-\frac{1}{(1+e^{-x})^2}\\<br>&amp;=\sigma(1-\sigma)\qquad \qquad   (13)<br>\end{align}</p>
<h3 id="4-Gradient-Descent"><a href="#4-Gradient-Descent" class="headerlink" title="4. Gradient Descent"></a>4. Gradient Descent</h3><p>We transfer the maximizing to a minimizing problem, we define the cost function:</p>
<p>$$J(\theta) = -\frac{1}{m}{\sum}_{i=1}^{m}[{yln(h_{\theta}(x)}) + (1-y)ln({1-h_{\theta}(x))}]\qquad (14) $$</p>
<p>if we want to minimize $J(\theta)$, we need know the gradient of $\frac{\partial J(\theta)}{\partial\theta_j}$, that is:<br>\begin{align}<br>\frac{\partial J(\theta)}{\partial\theta_j}<br>&amp;=\frac{\partial}{\partial\theta_j}(-\frac{1}{m}{\sum}_{i=1}^{m}[yln(h_\theta(x)) + (1-y)ln(1-h_\theta(x))])\\<br>&amp;= -\frac{1}{m}{\sum}_{i=1}^{m}[\frac{y}{h_\theta(x)} + \frac{y-1}{1-{h_\theta(x)}} ]\frac{\partial h_\theta (x)}{\partial\theta_j}\\<br>&amp;= -\frac{1}{m}{\sum}_{i=1}^{m}[{\frac{y}{\sigma}} + \frac{y-1}{1-\sigma} ]\frac{\partial\sigma}{\partial\theta_j}\\<br>&amp;= -\frac{1}{m}{\sum}_{i=1}^{m}[\frac{y-y\sigma}{\sigma(1-\sigma)} + \frac{\sigma y-\sigma}{\sigma(1-\sigma)}]\frac{\partial\sigma}{\partial\theta_j}\\<br>&amp;= -\frac{1}{m}{\sum}_{i=1}^{m}[\frac{y-\sigma}{\sigma\cdot(1-\sigma)}]\frac{\partial\sigma}{\partial\theta_j}\\<br>&amp;= -\frac{1}{m}{\sum}_{i=1}^{m}[\frac{y-\sigma}{\sigma(1-\sigma)}]\cdot\sigma(1-\sigma)\frac{\partial\Theta X}{\partial\theta_j}\\<br>&amp;= -\frac{1}{m}{\sum}_{i=1}^{m}[\frac{y-\sigma}{1}]\frac{\partial\Theta X}{\partial\theta_j}\\<br>&amp;= -\frac{1}{m}{\sum}_{i=1}^{m}[y-\sigma]{X_j}\\<br>&amp;= \frac{1}{m}{\sum}_{i=1}^{m}[h_{\theta}(x)-y]{X_j} \qquad(15)<br>\end{align}</p>
<p>Notice that the gradient descent is same as that of square cost function in Linear Regression, which is an extremely grace equation.</p>
<h3 id="Summarize"><a href="#Summarize" class="headerlink" title="Summarize"></a>Summarize</h3><p>Today We have talked about how to derive cost function of Logistic Regression, then we get the gradient descent equation of it. Next step is to use gradient descent to iterate the minimum of the cost function.</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ol>
<li><a href="https://www.coursera.org/learn/machine-learning/home/welcome" target="_blank" rel="noopener">https://www.coursera.org/learn/machine-learning/home/welcome</a></li>
<li>Parameter estimation for text analysis, Gregor Heinrich</li>
<li>Pattern Recognition and Machine Learning, Christopher M. Bishop</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/ML/" rel="tag"># ML</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/12/15/hello-world/" rel="next" title="Hello World">
                <i class="fa fa-chevron-left"></i> Hello World
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/02/25/Linear-Algebra-I/" rel="prev" title="Linear Algebra (I)">
                Linear Algebra (I) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Mingbo Cheng</p>
              <p class="site-description motion-element" itemprop="description">Mingbo</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Model-a-problem"><span class="nav-number">1.</span> <span class="nav-text">1. Model a problem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Estimate-Parameter"><span class="nav-number">2.</span> <span class="nav-text">2. Estimate Parameter</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Logistic-Regression"><span class="nav-number">3.</span> <span class="nav-text">3. Logistic Regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Gradient-Descent"><span class="nav-number">4.</span> <span class="nav-text">4. Gradient Descent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summarize"><span class="nav-number">5.</span> <span class="nav-text">Summarize</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-number">6.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mingbo Cheng</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
